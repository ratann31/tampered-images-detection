# ğŸ” Image Forgery Detection with Enhanced EfficientNetB7

**Image Forgery Detection** is a high-performance deep learning pipeline designed to identify manipulated (tampered) images with impressive precision and reliability. Leveraging the power of **EfficientNetB7** and **custom attention blocks**, the system excels at binary classification of authentic vs tampered images at scale.

---

## âœ¨ Features

- âœ… **EfficientNetB7 Backbone** for powerful feature extraction  
- ğŸ§  **Hybrid SE-CBAM Attention** for channel + spatial attention  
- ğŸ” **Enhanced Multi-Head Attention** with window-based spatial focus  
- âš™ï¸ **Mixed Precision + XLA** for optimized GPU training  
- ğŸ§ª **Advanced Data Augmentation** with photometric and geometric transforms  
- ğŸ“ˆ **Comprehensive Metrics** (Accuracy, AUC, Precision, Recall)  
- â±ï¸ **EarlyStopping** and **LearningRateScheduler** for better generalization  
- ğŸ“Š **TensorBoard Logging** for real-time training insights  
- ğŸ“¦ **Custom Data Split Script** for flexible training/validation/testing

---

## ğŸ—ï¸ Tech Stack

| Category           | Tech Used                     |
|--------------------|-------------------------------|
| Model Backbone     | EfficientNetB7 (Imagenet)     |
| Attention Layers   | Hybrid SE-CBAM, MHA Block     |
| Framework          | TensorFlow, Keras             |
| Data Handling      | tf.data, ImageDataGenerator   |
| Metrics/Callbacks  | AUC, Precision, Recall, EarlyStopping |
| Visualization      | TensorBoard                   |
| Optimization       | Mixed Precision, XLA          |
| Deployment Ready   | -                             |

---

## ğŸ—ƒï¸ Directory Structure

    â”œâ”€â”€ dataset/
       â”‚ â””â”€â”€ dataset/
             â”‚ â”œâ”€â”€ Authentic/
             â”‚ â””â”€â”€ Tampered/


    â”œâ”€â”€ split_dataset/
    â”‚ â”œâ”€â”€ train/
           â”œâ”€â”€ Authentic/
           â””â”€â”€ Tampered/

    â”‚ â”œâ”€â”€ val/
           â”œâ”€â”€ Authentic/
           â””â”€â”€ Tampered/

    â”‚ â””â”€â”€ test/
       â”œâ”€â”€ Authentic/
       â””â”€â”€ Tampered/





---

## ğŸ§ª Getting Started

### ğŸ“¦ Prerequisites

- Python 3.7+
- TensorFlow 2.10â€“2.14
- TensorFlow Addons
- Keras
- Compatible NVIDIA GPU or Google Colab

### ğŸ”§ Installation

     ```bash
       pip install tensorflow==2.10 keras tensorflow-addons scipy



------------------------------------------------------------------------------------------------------------------------------------------------------------------

ğŸ§  Model Architecture


ğŸ”¹ EfficientNetB7 (no top layer, pretrained on ImageNet)

ğŸ”¸ HybridSECBAM after initial convolutional blocks

ğŸ”¸ EnhancedMHABlock inserted mid-to-late layers

ğŸ”¹ Global Avg + Max Pooling

ğŸ”¹ Dense layers with Swish activation + Dropout

ğŸ”¸ Sigmoid output for binary classification


-------------------------------------------------------------------------------------------------------------------------------------------------------------------
Training Settings:

| Parameter 	|  Value|
|---------------|---------|
| Image Size	| 224 x 224|
| Batch Size	| 16      |
| Optimizer	| Adam (lr=1e-4)|
| Loss	    | Binary CrossEntropy|
| Callbacks	|  EarlyStopping, LR Scheduler|
| Mixed Precision	| âœ…      |

-------------------------------------------------------------------------------------------------------------------------------------------------------------------

ğŸ“ Notes

ğŸ”„  Make sure TensorFlow Addons is version-compatible (check TF Addons Compatibility Matrix)

ğŸ–¼ï¸  Works with datasets of 140K+ images or smaller custom datasets

ğŸ§ª  Designed for both research and production-level deployment


-------------------------------------------------------------------------------------------------------------------------------------------------------------------



ğŸ“š References

EfficientNet: [Rethinking Model Scaling](https://arxiv.org/abs/1905.11946)

CBAM: [Convolutional Block Attention Module](https://arxiv.org/abs/1807.06521)

TensorFlow Addons

-------------------------------------------------------------------------------------------------------------------------------------------------------------------

ğŸ“œ License

This project is licensed under the MIT License â€“ see the LICENSE file for details.
