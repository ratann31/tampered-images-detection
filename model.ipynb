{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8da2c57",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, GlobalAveragePooling2D, Dense, Conv2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "class HybridSECBAM(Layer):\n",
    "    def __init__(self, se_ratio=16, cbam_ratio=8, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.se_ratio = se_ratio\n",
    "        self.cbam_ratio = cbam_ratio\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'se_ratio': self.se_ratio,\n",
    "            'cbam_ratio': self.cbam_ratio,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        channels = input_shape[-1]\n",
    "        \n",
    "        # SE layers\n",
    "        self.se_dense1 = Dense(channels // self.se_ratio, activation='swish')\n",
    "        self.se_dense2 = Dense(channels, activation='sigmoid')\n",
    "\n",
    "        # CBAM channel attention MLP (shared for avg and max)\n",
    "        self.channel_mlp = Sequential([\n",
    "            Dense(channels // self.cbam_ratio, activation='swish'),\n",
    "            Dense(channels)\n",
    "        ])\n",
    "        \n",
    "        # CBAM spatial attention\n",
    "        self.spatial_conv = Conv2D(1, kernel_size=7, padding='same', activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "      dtype = inputs.dtype  # Match all tensors to this dtype\n",
    "\n",
    "       # --- SE ---\n",
    "      se = tf.reduce_mean(inputs, axis=[1, 2])\n",
    "      se = self.se_dense1(se)\n",
    "      se = self.se_dense2(se)\n",
    "      se = tf.reshape(se, [-1, 1, 1, inputs.shape[-1]])\n",
    "      se = tf.cast(se, dtype)\n",
    "\n",
    "      # --- CBAM Channel Attention ---\n",
    "      avg_pool = tf.reduce_mean(inputs, axis=[1, 2])\n",
    "      max_pool = tf.reduce_max(inputs, axis=[1, 2])\n",
    "      channel_att = tf.nn.sigmoid(self.channel_mlp(avg_pool) + self.channel_mlp(max_pool))\n",
    "      channel_att = tf.reshape(channel_att, [-1, 1, 1, inputs.shape[-1]])\n",
    "      channel_att = tf.cast(channel_att, dtype)\n",
    "\n",
    "      # --- CBAM Spatial Attention ---\n",
    "      avg_pool_spatial = tf.reduce_mean(inputs, axis=-1, keepdims=True)\n",
    "      max_pool_spatial = tf.reduce_max(inputs, axis=-1, keepdims=True)\n",
    "      concat = tf.concat([avg_pool_spatial, max_pool_spatial], axis=-1)\n",
    "      spatial_att = self.spatial_conv(concat)\n",
    "      spatial_att = tf.cast(spatial_att, dtype)\n",
    "\n",
    "      # --- Combine ---\n",
    "      out = inputs * se * channel_att * spatial_att\n",
    "      return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294cfe7e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, MultiHeadAttention, Conv2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow_addons.layers import GroupNormalization\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "class EnhancedMHABlock(Layer):\n",
    "    def __init__(self, num_heads=8, key_dim=64, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.key_dim = key_dim\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        channels = input_shape[-1]\n",
    "        if channels is None:\n",
    "            raise ValueError(\"Input channels must be defined.\")\n",
    "\n",
    "        self.mha = layers.MultiHeadAttention(\n",
    "            num_heads=self.num_heads,\n",
    "            key_dim=self.key_dim,\n",
    "            kernel_initializer='glorot_uniform',\n",
    "            bias_initializer='zeros'\n",
    "        )\n",
    "\n",
    "        self.ffn = Sequential([\n",
    "            Conv2D(4 * channels, kernel_size=1, activation='swish'),\n",
    "            Conv2D(channels, kernel_size=1)\n",
    "        ])\n",
    "\n",
    "        def get_valid_group_count(ch):\n",
    "            for g in reversed(range(1, 33)):\n",
    "                if ch % g == 0:\n",
    "                    return g\n",
    "            return 1\n",
    "\n",
    "        group_count = get_valid_group_count(channels)\n",
    "\n",
    "        self.norm1 = GroupNormalization(groups=group_count)\n",
    "        self.norm2 = GroupNormalization(groups=group_count)\n",
    "\n",
    "    def call(self, inputs):\n",
    "       dtype = inputs.dtype  # Consistently use the same dtype throughout\n",
    "\n",
    "       shape = tf.shape(inputs)\n",
    "       B, H, W, C = shape[0], shape[1], shape[2], shape[3]\n",
    "\n",
    "       x_flat = tf.reshape(inputs, [B, H * W, C])\n",
    "       attn = self.mha(x_flat, x_flat)\n",
    "       attn = tf.reshape(attn, [B, H, W, C])\n",
    "       attn = tf.cast(attn, dtype)\n",
    "\n",
    "       x = self.norm1(inputs + attn)\n",
    "       ffn_out = self.ffn(x)\n",
    "       return self.norm2(x + ffn_out)\n",
    "\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"key_dim\": self.key_dim,\n",
    "        })\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478b1f28",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from keras.applications import EfficientNetB7\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras import mixed_precision\n",
    "import tensorflow as tf\n",
    "\n",
    "def build_enhanced_model(img_size=(300, 300), num_classes=1):\n",
    "    base_model = EfficientNetB7(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(*img_size, 3)\n",
    "    )\n",
    "\n",
    "    # Feature extraction\n",
    "    block3_output = base_model.get_layer('block3a_project_bn').output\n",
    "    block5_output = base_model.get_layer('block5a_project_bn').output\n",
    "\n",
    "    # Attention pipeline\n",
    "    x3 = HybridSECBAM()(block3_output)\n",
    "    x3 = EnhancedMHABlock()(x3)\n",
    "    x3 = layers.MaxPooling2D(pool_size=2)(x3)\n",
    "\n",
    "    x5 = HybridSECBAM()(block5_output)\n",
    "    x5 = EnhancedMHABlock()(x5)\n",
    "\n",
    "    x = layers.Concatenate()([x3, x5])\n",
    "\n",
    "    max_pool = layers.GlobalMaxPooling2D()(x)\n",
    "    avg_pool = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Concatenate()([max_pool, avg_pool])\n",
    "\n",
    "    x = layers.Dense(512, activation='swish', dtype='float32')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(256, activation='swish', dtype='float32')(x)\n",
    "    output = layers.Dense(num_classes, activation='sigmoid', dtype='float32')(x)\n",
    "\n",
    "    model = models.Model(inputs=base_model.input, outputs=output)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Step 1: Make sure mixed precision is NOT enabled before model creation\n",
    "mixed_precision.set_global_policy('float32')\n",
    "\n",
    "# Step 2: Build the model\n",
    "model = build_enhanced_model(img_size=(224, 224), num_classes=1)\n",
    "\n",
    "# Step 3: Enable mixed precision globally (only after model is built)\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "\n",
    "# Step 4: Compile model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4, clipnorm=1.0)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad20a3f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.AUC(name='auc'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
